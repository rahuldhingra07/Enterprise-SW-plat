{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d723b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5545c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = pd.read_csv('C:\\\\Users\\\\rahul\\\\OneDrive\\\\Documents\\\\Enterprise\\\\train.csv')\n",
    "TestingData = pd.read_csv('C:\\\\Users\\\\rahul\\\\OneDrive\\\\Documents\\\\Enterprise\\\\test.csv')\n",
    "df = pd.concat([TrainingData, TestingData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5c601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary_characters(text):\n",
    "    text = re.sub(r'<.*?>', '', str(text))\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', str(text))\n",
    "    text = re.sub(r'\\s+', ' ', str(text)).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b63d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(remove_unnecessary_characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37224ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    try:\n",
    "        text = str(text)\n",
    "        tokens = word_tokenize(text)\n",
    "        return tokens\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing text: {e}\")\n",
    "        return []\n",
    "\n",
    "df['tokens'] = df['text'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437433ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    else:\n",
    "        text = str(text)\n",
    "    return text\n",
    "\n",
    "df['normalized_text'] = df['text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb2f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        words = text.split()        \n",
    "        filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "        filtered_text = ' '.join(filtered_words)\n",
    "    else:\n",
    "        filtered_text = ''\n",
    "    return filtered_text\n",
    "df['text_without_stopwords'] = df['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a26b8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ffb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['textID', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c7805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp(text):\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "333fcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selected_text'] = df[\"selected_text\"].apply(wp)\n",
    "X = df['selected_text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc61b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23c3a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 4  # Positive\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 2  # Neutral\n",
    "    else:\n",
    "        return 0  # Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f97417",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = X_test.apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f24024",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_numeric = y_test.map({'negative': 0, 'neutral': 2, 'positive': 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9bf54e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data Evaluation:\n",
      "Accuracy: 0.5589519650655022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.66      0.44      0.53      1572\n",
      "     Neutral       0.50      0.52      0.51      2236\n",
      "    Positive       0.58      0.72      0.64      1688\n",
      "\n",
      "    accuracy                           0.56      5496\n",
      "   macro avg       0.58      0.56      0.56      5496\n",
      "weighted avg       0.57      0.56      0.55      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest Data Evaluation:\")\n",
    "print('Accuracy:', accuracy_score(y_test_numeric, y_pred_test))\n",
    "print(classification_report(y_test_numeric, y_pred_test, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7550977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorization = TfidfVectorizer()\n",
    "XV_train = vectorization.fit_transform(X_train)\n",
    "XV_test = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbdcf135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(XV_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a386787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc = rfc.predict(XV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7f3c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114992721979621"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rfc = rfc.score(XV_test, y_test)\n",
    "score_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f879d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.75      0.77      1572\n",
      "     neutral       0.77      0.89      0.83      2236\n",
      "    positive       0.92      0.76      0.83      1688\n",
      "\n",
      "    accuracy                           0.81      5496\n",
      "   macro avg       0.82      0.80      0.81      5496\n",
      "weighted avg       0.82      0.81      0.81      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_rfc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, vectorizer):\n",
    "    \n",
    "    clean_text = wp(text)\n",
    "\n",
    "    text_vectorized = vectorizer.transform([clean_text])\n",
    "\n",
    "    prediction = model.predict(text_vectorized)[0]\n",
    "\n",
    "    sentiment_map = {\n",
    "        \"positive\": \"Positive\",\n",
    "        \"negative\": \"Negative\",\n",
    "        \"neutral\": \"Neutral\"\n",
    "    }\n",
    "\n",
    "    return sentiment_map.get(prediction.lower(), \"Unknown sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b237b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love this product, it's amazing!\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: This is the worst experience I've ever had.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: It's okay, not too bad but not great either.\n",
      "Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = \"I love this product, it's amazing!\"\n",
    "text2 = \"This is the worst experience I've ever had.\"\n",
    "text3 = \"It's okay, not too bad but not great either.\"\n",
    "\n",
    "print(f\"Text: {text1}\\nSentiment: {predict_sentiment(text1, rfc, vectorization)}\\n\")\n",
    "print(f\"Text: {text2}\\nSentiment: {predict_sentiment(text2, rfc, vectorization)}\\n\")\n",
    "print(f\"Text: {text3}\\nSentiment: {predict_sentiment(text3, rfc, vectorization)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d653494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text string (or type 'exit' to quit): I love my class\n",
      "Sentiment: Positive\n",
      "\n",
      "Enter a text string (or type 'exit' to quit): i hate my class\n",
      "Sentiment: Negative\n",
      "\n",
      "Enter a text string (or type 'exit' to quit): my class is okay\n",
      "Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of a given text string.\n",
    "\n",
    "    Parameters:\n",
    "    - text: The input text string.\n",
    "    - model: The trained machine learning model.\n",
    "    - vectorizer: The fitted TfidfVectorizer.\n",
    "\n",
    "    Returns:\n",
    "    - A string indicating whether the sentiment is \"Positive\", \"Negative\", or \"Neutral\".\n",
    "    \"\"\"\n",
    "    clean_text = wp(text)\n",
    "\n",
    "    text_vectorized = vectorizer.transform([clean_text])\n",
    "\n",
    "    prediction = model.predict(text_vectorized)[0]\n",
    "\n",
    "    sentiment_map = {\n",
    "        \"positive\": \"Positive\",\n",
    "        \"negative\": \"Negative\",\n",
    "        \"neutral\": \"Neutral\"\n",
    "    }\n",
    "\n",
    "    return sentiment_map.get(prediction.lower(), \"Unknown sentiment\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter a text string (or type 'exit' to quit): \")\n",
    "\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    sentiment = predict_sentiment(user_input, rfc, vectorization)\n",
    "\n",
    "    print(f\"Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d57e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
